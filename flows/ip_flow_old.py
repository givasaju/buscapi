# CORRE√á√ÉO FINAL COMPLETA

from crewai.flow.flow import Flow, listen, start
from pydantic import BaseModel
from typing import Dict, List, Any, Optional
import json
#import traceback

from agents.ip_agents import IPAgents
from tasks.ip_tasks import IPTaskManager
from database.persist_dados import BuscapiDB


class PropriedadeIntelectualState(BaseModel):
    """Estado do fluxo de propriedade intelectual."""
    search_criteria: str = ""
    raw_data: List[Dict[str, Any]] = []
    classified_data: List[Dict[str, Any]] = []
    analysis_results: Dict[str, Any] = {}
    visualizations: Dict[str, str] = {}
    insights: str = ""
    flow_id: str = ""


class PropriedadeIntelectualFlow(Flow[PropriedadeIntelectualState]):
    """Fluxo principal para an√°lise de propriedade intelectual."""

    def __init__(self, *args, **kwargs):
        """
        CR√çTICO: CrewAI Flow.__init__() N√ÉO ACEITA ARGUMENTOS!
        
        Este m√©todo foi modificado para capturar e corrigir automaticamente
        chamadas incorretas que passam argumentos.
        """
        
        # Se argumentos foram passados, extrair e armazenar para uso posterior
        search_criteria = None
        
        if args:
            print(f"‚ö†Ô∏è  AVISO: PropriedadeIntelectualFlow recebeu argumentos: {args}")
            # Assumir que o primeiro argumento √© search_criteria
            if len(args) >= 1 and isinstance(args[0], str):
                search_criteria = args[0]
                print(f"‚úÖ Extra√≠do search_criteria: {search_criteria}")
            
        if 'search_criteria' in kwargs:
            search_criteria = kwargs.pop('search_criteria')
            print(f"‚úÖ Extra√≠do search_criteria dos kwargs: {search_criteria}")
        
        # Chamar super().__init__() SEM argumentos (exig√™ncia do CrewAI)
        try:
            super().__init__()
        except Exception as e:
            print(f"‚ùå Erro ao inicializar Flow: {e}")
            # Se ainda der erro, tentar sem nenhum par√¢metro
            Flow.__init__(self)
        
        # Inicializar componentes b√°sicos
        self.agents = None
        self.task_manager = None
        self.db = None
        self.search_query_id = None
        self.raw_result_ids = []
        
        # Se search_criteria foi extra√≠do dos argumentos, configurar automaticamente
        if search_criteria:
            self._auto_setup(search_criteria)

    def _auto_setup(self, search_criteria: str):
        """Configura√ß√£o autom√°tica quando search_criteria √© passado no __init__."""
        try:
            print(f"üîß Configura√ß√£o autom√°tica para: {search_criteria}")
            self.setup_flow(search_criteria)
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro na configura√ß√£o autom√°tica: {e}")
            # Armazenar para configurar depois
            self._pending_search_criteria = search_criteria

    def setup_flow(self, search_criteria: str):
        """Configura o fluxo com crit√©rios de busca e inicializa banco."""
        try:
            # Configurar estado
            self.state.search_criteria = search_criteria
            
            # Inicializar componentes
            if not self.agents:
                self.agents = IPAgents()
            if not self.task_manager:
                self.task_manager = IPTaskManager(self.agents)
            
            # Inicializar conex√£o ao banco
            if not self.db:
                self.db = BuscapiDB(
                    dbname="buscapi_bd",
                    user="postgres",
                    password="givas2025",
                    host="localhost",
                    port=5432
                )
                
            # Registrar busca e armazenar search_query_id
            if not self.search_query_id:
                self.search_query_id = self.db.insert_search_query(
                    criteria=search_criteria, 
                    status='pending'
                )
            
            print(f"‚úÖ Fluxo configurado com sucesso para: {search_criteria}")
            
        except Exception as e:
            print(f"‚ùå Erro ao configurar fluxo: {e}")
            self.db = None
            self.search_query_id = None

    @start()
    def iniciar_pesquisa(self) -> str:
        """Inicia a pesquisa - configura√ß√£o autom√°tica se necess√°rio."""
        
        # Configura√ß√£o tardia se necess√°rio
        if hasattr(self, '_pending_search_criteria'):
            self.setup_flow(self._pending_search_criteria)
            delattr(self, '_pending_search_criteria')
        
        # Verificar se est√° configurado
        if not self.state.search_criteria:
            return "Erro: Crit√©rios de busca n√£o configurados"
        
        print(f"\nüöÄ Iniciando fluxo de an√°lise de propriedade intelectual")
        print(f"üìã Crit√©rios de busca: {self.state.search_criteria}")
        print(f"üÜî ID do fluxo: {self.state.id}")
        
        self.state.flow_id = str(self.state.id)
        
        if self.db and self.search_query_id:
            try:
                self.db.insert_search_log(self.search_query_id, "Fluxo iniciado.")
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao registrar log: {e}")
        
        return f"Fluxo iniciado para: {self.state.search_criteria}"

    @listen(iniciar_pesquisa)
    def coletar_dados(self, mensagem_inicial: str) -> str:
        """Coleta dados brutos."""
        print(f"\nüìä Coletando dados: {mensagem_inicial}")

        # Verificar se task_manager est√° dispon√≠vel
        if not self.task_manager:
            try:
                if not self.agents:
                    self.agents = IPAgents()
                self.task_manager = IPTaskManager(self.agents)
            except Exception as e:
                print(f"‚ùå Erro ao inicializar task_manager: {e}")
                return f"Erro na inicializa√ß√£o: {str(e)}"

        try:
            # Buscar explicitamente pelo tipo da ferramenta
            collection_task = self.task_manager.task_factory.create_data_collection_task(self.state.search_criteria)
            data_tool = next(t for t in collection_task.agent.tools if t.__class__.__name__ == "IPDataCollectorTool")
            raw_data_json = data_tool._run(self.state.search_criteria)

            try:
                raw_data = json.loads(raw_data_json)
                if isinstance(raw_data, dict):
                    raw_data = [raw_data]
            except Exception as e:
                print(f"Erro ao processar dados brutos: {e}")
                raw_data = []

            valid_raw_data = []
            valid_raw_result_ids = []
            
            for item in raw_data:
                if isinstance(item, dict) and "error" in item:
                    print(f"[WARN] Ignorando resultado bruto inv√°lido: {item.get('error')}")
                    continue
                valid_raw_data.append(item)
                
            # Persist√™ncia no banco (se dispon√≠vel)
            if self.db and self.search_query_id:
                for item in valid_raw_data:
                    try:
                        raw_id = self.db.insert_search_result_raw(
                            search_query_id=self.search_query_id,
                            source=item.get('source', 'unknown'),
                            raw_json=item
                        )
                        valid_raw_result_ids.append(raw_id)
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Erro ao salvar resultado bruto: {e}")

            if not valid_raw_data:
                print("‚ùå Nenhum dado bruto v√°lido coletado!")
                return "Erro: Nenhum dado bruto v√°lido coletado"

            self.state.raw_data = valid_raw_data
            self.raw_result_ids = valid_raw_result_ids

            if self.db and self.search_query_id:
                try:
                    self.db.insert_search_log(self.search_query_id, f"{len(valid_raw_data)} resultados brutos persistidos.")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro ao registrar log: {e}")

            print(f"‚úÖ Coletados {len(valid_raw_data)} registros v√°lidos")
            return f"Dados coletados: {len(valid_raw_data)} registros v√°lidos"
            
        except Exception as e:
            error_msg = f"Erro na coleta de dados: {str(e)}"
            print(f"‚ùå {error_msg}")
            if self.db and self.search_query_id:
                try:
                    self.db.insert_search_log(self.search_query_id, f"Erro na coleta: {str(e)}")
                except:
                    pass
            return error_msg

    @listen(coletar_dados)
    def classificar_dados(self, resultado_coleta: str) -> str:
        """Classifica os dados coletados."""
        print(f"\nüè∑Ô∏è Classificando dados: {resultado_coleta}")
        
        if not self.state.raw_data:
            return "Nenhum dado para classificar"
            
        try:
            classification_task = self.task_manager.task_factory.create_data_classification_task()
            classified_data_json = classification_task.agent.tools[0]._run(json.dumps(self.state.raw_data))
            classified_data = json.loads(classified_data_json)

            valid_classified_data = []
            count_saved = 0
            
            for idx, item in enumerate(classified_data):
                if not item or (isinstance(item, dict) and "error" in item):
                    print(f"[WARN] Ignorando resultado classificado inv√°lido")
                    continue
                    
                raw_id = self.raw_result_ids[idx] if idx < len(self.raw_result_ids) else None
                if raw_id is None:
                    print(f"[WARN] Sem raw_result_id correspondente")
                    continue

                # Salvar no banco se dispon√≠vel
                if self.db:
                    try:
                        self.db.insert_search_result_structured(
                            search_result_raw_id=raw_id,
                            category=item.get("category", "Outros"),
                            title=item.get("title", ""),
                            date_found=item.get("filingDate") or item.get("publicationDate"),
                            applicant=item.get("applicantName") or item.get("applicant", ""),
                            summary=item.get("abstract") or item.get("summary", ""),
                            structured_json=item
                        )
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Erro ao salvar classificado: {e}")
                        
                valid_classified_data.append(item)
                count_saved += 1

            self.state.classified_data = valid_classified_data
            
            if self.db and self.search_query_id:
                try:
                    self.db.insert_search_log(self.search_query_id, f"{count_saved} resultados classificados persistidos.")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro ao registrar log: {e}")

            print(f"‚úÖ Classifica√ß√£o conclu√≠da: {count_saved} registros v√°lidos")
            return f"Classifica√ß√£o conclu√≠da: {count_saved} registros v√°lidos"
            
        except Exception as e:
            error_msg = f"Erro na classifica√ß√£o: {str(e)}"
            print(f"‚ùå {error_msg}")
            if self.db and self.search_query_id:
                try:
                    self.db.insert_search_log(self.search_query_id, error_msg)
                except:
                    pass
            return error_msg

    @listen(classificar_dados)
    def analisar_dados(self, resultado_classificacao: str) -> str:
        """Analisa os dados classificados."""
        print(f"\nüìà Analisando dados: {resultado_classificacao}")
        
        if not self.state.classified_data:
            return "Nenhum dado classificado para analisar"
            
        try:
            analysis_task = self.task_manager.task_factory.create_analysis_task()
            analysis_results_json = analysis_task.agent.tools[0]._run(json.dumps(self.state.classified_data))
            self.state.analysis_results = json.loads(analysis_results_json)

            # Gerar insights
            insights = self._generate_insights_from_analysis()
            self.state.insights = insights

            if self.db and self.search_query_id:
                try:
                    self.db.insert_search_log(self.search_query_id, "An√°lise conclu√≠da com sucesso.")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro ao registrar log: {e}")

            print(f"‚úÖ An√°lise conclu√≠da com {len(self.state.analysis_results)} m√©tricas")
            return f"An√°lise conclu√≠da: {insights[:100]}..."
            
        except Exception as e:
            error_msg = f"Erro na an√°lise: {str(e)}"
            print(f"‚ùå {error_msg}")
            if self.db and self.search_query_id:
                try:
                    self.db.insert_search_log(self.search_query_id, error_msg)
                except:
                    pass
            return error_msg

    @listen(analisar_dados)
    def gerar_visualizacoes(self, resultado_analise: str) -> str:
        """Gera visualiza√ß√µes dos dados."""
        print(f"\nüìä Gerando visualiza√ß√µes: {resultado_analise}")
        
        if not self.state.analysis_results:
            return "Nenhum resultado de an√°lise para visualizar"
            
        try:
            visualization_task = self.task_manager.task_factory.create_visualization_task()
            visualizations = {}

            if "count_by_category" in self.state.analysis_results:
                try:
                    bar_chart = visualization_task.agent.tools[1]._run(
                        json.dumps(self.state.analysis_results),
                        "bar",
                        "category_distribution.png",
                    )
                    visualizations["category_chart"] = bar_chart
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro ao gerar gr√°fico de categorias: {e}")

            if "count_by_year" in self.state.analysis_results:
                try:
                    line_chart = visualization_task.agent.tools[1]._run(
                        json.dumps(self.state.analysis_results),
                        "line",
                        "yearly_trends.png",
                    )
                    visualizations["trend_chart"] = line_chart
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro ao gerar gr√°fico de tend√™ncias: {e}")

            self.state.visualizations = visualizations
            
            if self.db and self.search_query_id:
                try:
                    self.db.insert_search_log(self.search_query_id, f"{len(visualizations)} visualiza√ß√µes geradas.")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro ao registrar log: {e}")

            print(f"‚úÖ Visualiza√ß√µes geradas: {len(visualizations)} gr√°ficos")
            return f"Visualiza√ß√µes prontas: {list(visualizations.keys())}"
            
        except Exception as e:
            error_msg = f"Erro nas visualiza√ß√µes: {str(e)}"
            print(f"‚ùå {error_msg}")
            if self.db and self.search_query_id:
                try:
                    self.db.insert_search_log(self.search_query_id, error_msg)
                except:
                    pass
            return error_msg

    def _generate_insights_from_analysis(self) -> str:
        """Gera insights baseados na an√°lise."""
        insights = []
        
        try:
            if "count_by_category" in self.state.analysis_results:
                categories = self.state.analysis_results["count_by_category"]
                if categories:
                    total = sum(categories.values())
                    most_common = max(categories, key=categories.get)
                    insights.append(
                        f"A categoria mais comum √© '{most_common}' com {categories[most_common]} registros"
                        f" ({categories[most_common] / total * 100:.1f}% do total)."
                    )
                    
            if "count_by_year" in self.state.analysis_results:
                years = self.state.analysis_results["count_by_year"]
                if years and len(years) > 1:
                    years_sorted = sorted(years.items())
                    trend = (
                        "crescente"
                        if years_sorted[-1][1] > years_sorted[0][1]
                        else "decrescente"
                    )
                    insights.append(
                        f"A tend√™ncia temporal √© {trend}, com {years_sorted[-1][1]} registros "
                        f"no ano mais recente ({years_sorted[-1][0]})."
                    )
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao gerar insights: {e}")
            
        return " ".join(insights) if insights else "An√°lise conclu√≠da com dados b√°sicos."

    def get_final_report(self) -> Dict[str, Any]:
        """Gera relat√≥rio final."""
        # Atualizar status no banco
        if self.db and self.search_query_id:
            try:
                self.db.update_search_query_status(self.search_query_id, "completed")
                self.db.insert_search_log(self.search_query_id, "Busca marcada como conclu√≠da.")
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao atualizar status: {e}")

        return {
            "flow_id": self.state.flow_id,
            "search_criteria": self.state.search_criteria,
            "data_collected": len(self.state.raw_data),
            "classified_data": self.state.classified_data, # <-- ADICIONADO: A lista de dados
            "analysis_results": self.state.analysis_results,
            "insights": self.state.insights,
            "visualizations": self.state.visualizations,
            "status": "completed",
        }


# GERENCIADOR CORRIGIDO
class IPFlowManager:
    """Gerenciador para m√∫ltiplos fluxos de propriedade intelectual."""
    
    def __init__(self):
        self.active_flows = {}
    
    def create_flow(self, flow_id: str, search_criteria: str) -> PropriedadeIntelectualFlow:
        """
        Cria um novo fluxo.
        ‚úÖ SUPORTA AMBAS AS FORMAS: com e sem argumentos
        """
        try:
            # Tentar criar sem argumentos (modo correto CrewAI)
            flow = PropriedadeIntelectualFlow()
            flow.setup_flow(search_criteria)
        except Exception as e:
            print(f"‚ö†Ô∏è  Modo sem argumentos falhou: {e}")
            try:
                # Fallback: usar o __init__ modificado que aceita argumentos
                flow = PropriedadeIntelectualFlow(search_criteria)
            except Exception as e2:
                print(f"‚ùå Ambos os modos falharam: {e2}")
                raise e2
        
        self.active_flows[flow_id] = flow
        return flow
    
    def get_flow(self, flow_id: str) -> Optional[PropriedadeIntelectualFlow]:
        """Retorna um fluxo espec√≠fico."""
        return self.active_flows.get(flow_id)
    
    def execute_flow(self, flow_id: str) -> Dict[str, Any]:
        """Executa um fluxo completo."""
        flow = self.get_flow(flow_id)
        if not flow:
            return {"error": "Fluxo n√£o encontrado"}

        try:
            result = flow.kickoff()
            return flow.get_final_report()
        except Exception as e:
            print(f"‚ùå Erro na execu√ß√£o do fluxo: {e}")
            return {"error": f"Erro na execu√ß√£o do fluxo: {str(e)}"}
    
    def list_flows(self) -> List[str]:
        """Lista todos os fluxos ativos."""
        return list(self.active_flows.keys())


# CLASSE DE SERVI√áO CORRIGIDA
class IPAnalysisService:
    """Servi√ßo principal de an√°lise de PI."""
    
    def __init__(self, category_rules_file: str = "data/category_rules.json"):
        """
        Inicializa o servi√ßo de an√°lise de PI.
        
        Args:
            category_rules_file: Caminho para o arquivo de regras de categoriza√ß√£o
        """
        # Inicializar o gerenciador de fluxos
        self.flow_manager = IPFlowManager()
        
        # Carregar regras de categoriza√ß√£o
        self.category_rules_file = category_rules_file
        self.category_rules = self._load_category_rules()
        
        # Contador para IDs √∫nicos de fluxo
        self._flow_counter = 0

    def _load_category_rules(self) -> Dict[str, Any]:
        """Carrega regras de categoriza√ß√£o."""
        try:
            with open(self.category_rules_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"‚ö†Ô∏è  Arquivo de regras n√£o encontrado: {self.category_rules_file}")
            return {}
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao carregar regras: {e}")
            return {}

    def start_analysis(self, search_criteria: str) -> str:
        """Inicia uma nova an√°lise."""
        self._flow_counter += 1
        flow_id = f"flow_{self._flow_counter:03d}"
        
        try:
            flow = self.flow_manager.create_flow(flow_id, search_criteria)
            print(f"‚úÖ Fluxo {flow_id} criado com sucesso")
            return flow_id
        except Exception as e:
            print(f"‚ùå Erro ao criar fluxo: {e}")
            return f"error_{flow_id}"

    def execute_analysis(self, flow_id: str) -> Dict[str, Any]:
        """Executa uma an√°lise completa."""
        return self.flow_manager.execute_flow(flow_id)

    def get_flow_status(self, flow_id: str) -> Dict[str, Any]:
        """Obt√©m status de um fluxo."""
        flow = self.flow_manager.get_flow(flow_id)
        if not flow:
            return {"error": "Fluxo n√£o encontrado"}
        
        return {
            "flow_id": flow_id,
            "search_criteria": flow.state.search_criteria,
            "raw_data_count": len(flow.state.raw_data),
            "classified_data_count": len(flow.state.classified_data),
            "has_analysis": bool(flow.state.analysis_results),
            "has_visualizations": bool(flow.state.visualizations)
        }